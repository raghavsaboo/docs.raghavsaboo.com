{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Hello  </p>"},{"location":"Non-Technical/Areas%20of%20Interest/","title":"Areas of Interest","text":"<ul> <li>Story Telling<ul> <li>Writing</li> <li>Spoken Delivery</li> </ul> </li> <li>Psychology</li> <li>Business</li> </ul>"},{"location":"Non-Technical/Business/Books/The%20Personal%20MBA%20by%20Josh%20Kaufman/","title":"The Personal MBA by Rory Sutherland","text":"<p>Link: The Personal MBA</p>"},{"location":"Non-Technical/Business/Books/The%20Personal%20MBA%20by%20Josh%20Kaufman/#value-creation","title":"Value Creation","text":"<p>The key to value creation is to link a repeatable process that combines</p> <ol> <li>Value Creation - actually discovering and building something that people want</li> <li>Marketing - driving attention to it</li> <li>Sales - convert interest into paying customers</li> <li>Value Delivery - ensure customers are satisfied with what you promised</li> <li>Finance - sustain the process throug profit</li> </ol> <p>with the needs of the market which can fall into one of the following human drives</p> <ol> <li>The Drive to Acquire</li> <li>The Drive to Bond</li> <li>The Drive to Learn</li> <li>The Drive to Defend</li> <li>The Drive to Feel</li> </ol>"},{"location":"Non-Technical/Psychology/Books/Alchemy%3A%20The%20Dark%20Art%20and%20Curious%20Science%20of%20Creating%20Magin%20in%20Brands%2C%20Business%2C%20and%20Life/","title":"Alchemy by Rory Sutherland","text":"<p>Link: Good Reads</p>"},{"location":"Non-Technical/Psychology/Books/Alchemy%3A%20The%20Dark%20Art%20and%20Curious%20Science%20of%20Creating%20Magin%20in%20Brands%2C%20Business%2C%20and%20Life/#overview","title":"Overview","text":"<p>The main premise of the book is that while science and logic has resulted in immensely valuable products, there is a treasure trove still waiting to be discovered by applying apparently illogical solutions to human problems.</p> <ul> <li>Just because the scientific methodology has been so reliable it does not have to be the only tool to apply especially to a messy field like human behaviour.</li> <li>\"Engineering does not allow for magic. Psychology does.\"</li> <li>Rory defines the way humans make decisions as \"psycho-logic\" - to distinguish it from the concepts of \"logic\" and \"rationality\"</li> <li>The idea is to become adept at spotting instances where the \"universal laws\" don't apply - when abandoning logic is sensible</li> </ul> <p>A 4x4 matrix that can be plotted of human advances / ideas that fall on a spectrum between FAILS to WORKS and SEEMS WEIRD to MAKES SENSE.</p> <p>e.g. Bicycles definitely work but are at the same time very weird - humans have learned how to ride bicycles but it is not built in a \"logical\" manner.</p>"},{"location":"Non-Technical/Psychology/Books/Alchemy%3A%20The%20Dark%20Art%20and%20Curious%20Science%20of%20Creating%20Magin%20in%20Brands%2C%20Business%2C%20and%20Life/#signalling","title":"Signalling","text":""},{"location":"Non-Technical/Psychology/Books/Alchemy%3A%20The%20Dark%20Art%20and%20Curious%20Science%20of%20Creating%20Magin%20in%20Brands%2C%20Business%2C%20and%20Life/#subconcious-hacking","title":"Subconcious Hacking","text":""},{"location":"Non-Technical/Psychology/Books/Alchemy%3A%20The%20Dark%20Art%20and%20Curious%20Science%20of%20Creating%20Magin%20in%20Brands%2C%20Business%2C%20and%20Life/#satisficing","title":"Satisficing","text":""},{"location":"Non-Technical/Psychology/Books/Alchemy%3A%20The%20Dark%20Art%20and%20Curious%20Science%20of%20Creating%20Magin%20in%20Brands%2C%20Business%2C%20and%20Life/#psychophysics","title":"Psychophysics","text":""},{"location":"Non-Technical/Story%20Telling/Books/Storyworthy%20by%20Matthew%20Dicks/","title":"Storyworthy by Matthew Dicks","text":"<p>Link: Matthew Dicks Official Site</p>"},{"location":"Non-Technical/Story%20Telling/Books/Storyworthy%20by%20Matthew%20Dicks/#how-to-brainstorm-story-ideas","title":"How to Brainstorm Story Ideas","text":""},{"location":"Non-Technical/Story%20Telling/Books/Storyworthy%20by%20Matthew%20Dicks/#homework-for-life","title":"Homework for Life","text":"<ul> <li>Spend 5 minutes each day to write 2-3 sentences - not the entire story - of moments from the day</li> <li>Don't worry of connecting threads of stories from previous days</li> </ul>"},{"location":"Non-Technical/Story%20Telling/Books/Storyworthy%20by%20Matthew%20Dicks/#crash-burn","title":"Crash &amp; Burn","text":"<ul> <li>Spend 10 minutes to allow yourself to write your stream of conciousness/thoughts</li> <li>Don't let your pen from stopping - let new ideas keep crashing in without hesitation or judgement</li> <li>Be willing to leave a good idea behind in favour of a new one - even if the new idea is bad</li> </ul>"},{"location":"Non-Technical/Story%20Telling/Books/Storyworthy%20by%20Matthew%20Dicks/#first-best-last-worst","title":"First, Best, Last, Worst","text":"<ul> <li>A story against each of these prompts e.g. <code>First/Best/Last/Worst Car</code></li> <li>Annotate any as potential story or anecdote</li> <li>But not all listed will be story worthy</li> </ul>"},{"location":"Technical/Areas%20of%20Interest/","title":"Areas of Interest","text":"<ul> <li>Algorithms</li> <li>Data Structures</li> <li>Statistics</li> <li>Linear Algebra</li> <li>Calculus</li> <li>Machine Learning</li> <li>Distributed Systems Design</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Compressed%20Notes/","title":"Compressed Notes","text":""},{"location":"Technical/Distributed%20Systems%20Design/Data%20Models/","title":"Data Models","text":""},{"location":"Technical/Distributed%20Systems%20Design/Data%20Models/#overview","title":"Overview","text":"<p>Data Modeling (how data is stored) and Data Querying (how data is retrieved) choices  go hand in hand.</p>"},{"location":"Technical/Distributed%20Systems%20Design/Data%20Models/#data-abstractions","title":"Data Abstractions","text":""},{"location":"Technical/Distributed%20Systems%20Design/Data%20Models/#main-categories-of-databases","title":"Main Categories of Databases","text":""},{"location":"Technical/Distributed%20Systems%20Design/Data%20Models/#1-relational-database","title":"1. Relational Database","text":"<p>When you have a relatively fixed structure and you know this structure is not going to change too rapidly.</p> <ul> <li>Optimized for Transaction and Batch Processing (Read Throughput), Joins etc.</li> <li>Data Organized as tables/relations</li> <li>Object Relational Mapping Needed</li> <li>Oracle, MySQL, PostgreSQL</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Data%20Models/#2-document-database","title":"2. Document Database","text":"<p>Target use cases are where data comes in self-constrained documents and relationships between one document and another are rare. Also the schema is easily evolved.</p> <ul> <li>NoSQL - or not only SQL</li> <li>Flexible schemas, better performance due to locality / high write throughput</li> <li>Mainly free and open source</li> <li>MongoDB, CouchDB, Espresso</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Data%20Models/#3-graph-database","title":"3. Graph Database","text":"<p>Target use cases are where anything is potentially related to everything.</p> <ul> <li>Best suited for highly interconnected data - many to many relationships</li> <li>Social graphs, web graphs etc.</li> <li>Neo4j, SPARQL, Cypher</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Overview/","title":"Overview","text":"<p>Data intensive applications are one where:</p> <ol> <li>the amount of data that is generated/uses increases quickly OR</li> <li>the complexity of data generated/used increases quickly OR</li> <li>the speed of change in data increases quickly</li> </ol>"},{"location":"Technical/Distributed%20Systems%20Design/Overview/#key-components-of-modern-data-intensive-applications","title":"Key Components of Modern Data Intensive Applications","text":"<ol> <li>Database - source of truth for any consumer.</li> <li>Cache - for temporarily storing an expensive operation to speed up reads</li> <li>Full-text index - for quickly seasrching data by keyword or filter</li> <li>Message queues - for message passing between processes.</li> <li>Stream processing - near/realtime processing of data</li> <li>Batch processing - crunching large amounts of collected data</li> <li>Application code - logic and connective tissue between the components above</li> </ol>"},{"location":"Technical/Distributed%20Systems%20Design/Overview/#key-requirements-for-data-intensive-applications","title":"Key Requirements for Data Intensive Applications","text":""},{"location":"Technical/Distributed%20Systems%20Design/Overview/#reliability","title":"Reliability","text":"<ul> <li>Fault tolerance</li> <li>No un-authorized access</li> <li>Chaos testing</li> <li>Full machine failures</li> <li>Bugs - Automating tests</li> <li>Staging/Testing environment</li> <li>Quickly roll-back</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Overview/#scalability","title":"Scalability","text":"<ul> <li>Handle higher traffic volume</li> <li>Meeting traffic load with peak number of reads, writes and simultaneous users</li> <li>Capacity planning</li> <li>Response time vs throughput</li> <li>End user response = server response time + network response time</li> <li>90th, 95th Percentile Service Level Objectives (SLOs) / Service Level Agreements (SLAs)</li> <li>Scaling</li> <li>up (more powerful machine)</li> <li>out (distributed over many smaller machines)</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Overview/#maintainability","title":"Maintainability","text":"<ul> <li>Add new people to work</li> <li>Productivity</li> <li>Operable: Configurable and testable</li> <li>Simple: Easy to understand and ramp up</li> <li>Evolveable: East to change</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Partitioning/","title":"Partitioning","text":""},{"location":"Technical/Distributed%20Systems%20Design/Partitioning/#overview","title":"Overview","text":"<p>Horizontally scaling and scalability (data, users, and machines) is the key theme of partitioning.</p> <p>Partitioning == Splitting == Sharding</p>"},{"location":"Technical/Distributed%20Systems%20Design/Partitioning/#key-issues-to-look-out-for","title":"Key Issues to Look Out For","text":"<ul> <li>Hot spots / Skews</li> <li>Key Hash Based Partition</li> <li>Rebalancing strategies</li> <li>Routing Logic Placement</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Partitioning/#_1","title":"Partitioning","text":""},{"location":"Technical/Distributed%20Systems%20Design/Replication/","title":"Replication","text":""},{"location":"Technical/Distributed%20Systems%20Design/Replication/#overview","title":"Overview","text":"<p>The process of syncing data between databases in a consistent way is refered to as \"replication\". </p> <p>This is needed due to a few reasons: * Resilience of service to Machine Failures * Improving latency for global audience * Scaling to millions of users * Offline/Network failures</p>"},{"location":"Technical/Distributed%20Systems%20Design/Replication/#types-of-replication","title":"Types of Replication","text":""},{"location":"Technical/Distributed%20Systems%20Design/Replication/#1-single-leader","title":"1. Single Leader","text":""},{"location":"Technical/Distributed%20Systems%20Design/Replication/#2-multi-leader","title":"2. Multi-Leader","text":""},{"location":"Technical/Distributed%20Systems%20Design/Replication/#3-leaderless","title":"3. Leaderless","text":""},{"location":"Technical/Distributed%20Systems%20Design/Storage%20and%20Retrieval/","title":"Storage and Retrieval","text":""},{"location":"Technical/Distributed%20Systems%20Design/Storage%20and%20Retrieval/#which-database-to-use","title":"Which Database to Use?","text":"<ul> <li>Every storage engine is optimized for different use cases. Select the right storage  engine for your use case</li> <li>As an application developer we need to have a rough idea on what the storage engine is doing under the hood</li> <li>Tuning and optimizing pointers</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Storage%20and%20Retrieval/#categories-of-databases","title":"Categories of Databases","text":"<p>There are two main categories of databases - OLTP (Online Transaction Processing Database) and OLAP (Online Analytical Processing Database) each with a different read pattern,  write patterns, user using it, data size etc.</p> <ol> <li>OLTP - Online Transaction Processing Database optimized for latency.<ul> <li>eg. MySQL</li> <li>Usually row-order store<ul> <li>easy to modify/add a record</li> <li>might read in unnecessary data</li> </ul> </li> </ul> </li> <li>OLAP - Online Analytical Processing Databases optimized for data crunching.<ul> <li>Data Warehousing (Star/Snowflake schema), column oriented</li> <li>Column compression, data cubes, optimized for reads/queries</li> <li>Materialized views, lack of flexibility</li> <li>HBase, Hive, Spark</li> <li>Usually column-order store<ul> <li>Only need to read in relevant data</li> <li>Tuple writes require multiple acesses</li> <li>Suitable for read-mostly, read-intensive, large data repositories</li> </ul> </li> </ul> </li> </ol>"},{"location":"Technical/Distributed%20Systems%20Design/Storage%20and%20Retrieval/#database-index","title":"Database Index","text":"<ul> <li>An index is an additional structure that is derived from the primary data. A well chosen index optimizes for reads but slows down the write.</li> <li>Simple database index is a Hash based Index. Some issues for an index:</li> <li>File format (encoding)</li> <li>Deleting records</li> <li>Crash recovery</li> <li>Partially written records</li> <li>Concurrency control</li> <li>Range queries?</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Storage%20and%20Retrieval/#types-of-storage-engines","title":"Types of Storage Engines","text":"<ul> <li>Two families of storage engines used by databases:</li> <li>Log structured - LSM-Trees e.g. SSTables -&gt; HBASE, Cassandra</li> <li>Page-Oriented - B-trees -&gt; RDBMS</li> <li>These are answers to limitations of disk access.</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Storage%20and%20Retrieval/#lsm-trees-log-sort-merge-and-sstables-sort-string-tables","title":"LSM-Trees (Log Sort Merge) and SSTables (Sort String Tables)","text":"<ul> <li>SSTables - in-memory mem table backend by Disk SSTable file, sorted by keys.</li> <li>e.g. Red-Black tree or AVL trees. Supports high write throughput.</li> <li>Lucene - full-text search is much more complex than key-value index like SSTables. However, it does internally use SSTables for term dictionary.</li> <li>Bloom filters - memory efficient data structure used for approximating the contents of a set. It can tell you if a key does not appear in the database, thus saves many unnecessary disk reads for non-existent keys.</li> <li>Compaction is a background process of the means of throwing away duplicate keys in the log and keeping only the most recent update for each key.</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Storage%20and%20Retrieval/#b-trees-index","title":"B-Trees Index","text":"<ul> <li>Most widely used indexing structure is B-Trees. One place per key!</li> <li>They are the standard implementation in RDBMS and NoSQL stores today.</li> <li>It also keeps key-value sorted by keys which allows quick lookups.</li> <li>B-Trees are designed and optimized for the hardward as disks are arranged in fixed sized blocks, B-Trees also break down the data into fixed size 4KB blocks. There is a root node and a branching factor (references to child pages)</li> <li>4 level tree with 4KB pages with branching factor of 500 can store up to 256TB! B-Tree is optimized for reads!</li> <li>Write ahead log is used for crash recovery, latches for concurrency.</li> <li>Sibling references in child node allows for easier scannig of sequential keys.</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Storage%20and%20Retrieval/#other-indexing-concepts","title":"Other Indexing Concepts","text":"<ul> <li>Clustered index - inline storing of row values</li> <li>Secondary index - helps with joins</li> <li>Covering index - few columns are included</li> <li>Multi-column index - multiple keys concatenated</li> <li>Full-text search and fuzzy indexes help with spelling mistakes (edit distances), grammar, synonyms, words near each other, linguistics etc.</li> <li>In Memory Stores - Redis, Memcaches etc.</li> </ul>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/","title":"Basic Probability and Statistics","text":"<p>P(A): probability of A P(A'): probability of not A (the complement) P(A, B): probability of A and B occuring together</p>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#basic-principles","title":"Basic Principles","text":"<ul> <li>P(A) &lt;= 1</li> <li>P(A') = 1 - P(A)</li> <li>P(A or B) = P(A) + P(B) - P(A and B)</li> </ul>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#conditional-probability","title":"Conditional Probability","text":"<p>P(A|B) = P(A and B) / P(B)</p> <p>Example: A: number of fatalities B: number of people whose age is between 40-49 P(A and B): number of fatalities for people whose age is between 40-49</p> <p>P(A|B) = P(A and B) / P(B)</p> <p>P(A|B) != P(A) as higher age groups tend to have higher fatality rate</p>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#independence","title":"Independence","text":"<p>If A and B are independent (not correlated) then P(A and B) = P(A)P(B) and P(A|B) = P(A)</p>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#conditional-independence","title":"Conditional Independence","text":"<p>[Typical Independence] Suppose Alice and Malice each toss separate die. A is Alice's outcome and B is Malice's outcome. Knowing Alice's outcome provides no information about Malice's outcome.</p> <p>However if Alice and Malice toss the same dice, and the dice is biased toward showing some numbers, then knowing Alice's outcome provide some information about Malice's outcome can be inferred.</p> <p>Independece does not hold A\u27c2B | C if P(A|B, C) = P(A|C)</p> <p>Given the information of C, B contributes no information about A.</p> <p>If P(C) is the distribution for outcomes for the shared dice, then B\u27c2A | C - i.e. knowing Alice's outcome A gives no additional informaiton about Malice's outcome B. Therefore P(B|(A, C)) = P(B|C).</p> <p>Another Example: <pre><code>graph TD\n    A --&gt; B;\n    A --&gt; C;\n    C --&gt; E;\n    D --&gt; E;\n\n  subgraph \"Stats Knowledge\";\n    A[Statistics];\n    B[Causal Inference];\n    C[Machine Learning];\n  end\n\n  subgraph \"Job Requirement\";\n    C[Machine Learning];\n    D[SQL Skill];\n    E[Job Offer];\n  end</code></pre></p> <ul> <li>knowledge of statistics means you know more about causal inference and machine learning</li> <li>to get a job offer you need to know either machine learning or SQL</li> <li>B is not independent of C - if you are good at causal inference, you are probably good at statistics, and likely good at machine learning</li> <li>B is independent of C given/conditioned on A - if you know someones level of statistics, you can infer machine learning skills and knowledge of causal inference will not give any further information</li> <li>C is independent of D - knowing how good you are at machine learning tells me nothing about how good you are at SQL</li> <li>C is not conditionally independent of D given E - given you get a job offer, knowing how good you are at ML gives me an idea about your SQL skills</li> </ul>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#simpsons-paradox","title":"Simpson's Paradox","text":"<p>It can be that for all age groups, fatality rate in Italy is lower than those in China, but the overall fatality rate in Italy is higher than in China.</p> <p>This is because Age is a confounding factor - causing the Simpson Paradox. Italian population is generally older than the Chinese population.</p> <pre><code>graph LR\n    Country --&gt; Age\n    Country --&gt; Fatality\n    Age --&gt; Fatality</code></pre>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#potential-outcomes-framework","title":"Potential Outcomes Framework","text":"<p>For a set of i.i.d. subjects \\(i = 1, ..., n\\) we observe a tuple \\((X_i, Y_i, W_i)\\) comprised of: - a feature vector \\(X_i\\) - a response or potential outcomes \\(Y_i\\) - a treatment assignment \\(T_i\\)</p> <p>The goal is to estimate the Causal Estimand or Causal Effect of Treatment. However we only get to observe one outcome for each \\(i\\) i.e. \\(Y_i = Y_i(T_i)\\) - you are either treated or not treated. - This is the \"missingness\" issue in causal inference</p> <pre><code>graph LR\n    A[Causal Estimand] --&gt; |Identificaiton| B[Statistical Estimand]\n    B[Statistical Estimand] --&gt; |Estimation| C[Estimate]</code></pre> <ul> <li>Causal Estimand or Causal Effect of Treatment: \\(E[Y(1) - Y(0)]\\)</li> <li>Statistical Estimand: \\(E_X[E[Y|T=1, X] - E[Y|T=0, X]]\\)</li> <li>Estimate: \\(Average(Average(Y_i|T_i=1)) - Average(Y_i|T_i=0))\\)</li> </ul>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#average-treatment-effect-ate","title":"Average Treatment Effect - ATE","text":"<p>The causal effect of treatment is the average treatment effect i.e. \\(E[Y(1) - Y(0)]\\).</p> <p>However we cannot observe treatment and control outcomes for all subjects \\(i\\).</p> <p>Approach 1: Pure Randomized Control Trial - we assume that \\((Y_0, Y_1) \\bot T\\) - the potential outcomes are independent of the treatment assignment - in an RCT we get the following: \\(E[Y_i(1)] - E[Y_i(0)] = E[Y_i(1)|T_i=1] - E[Y_i(0)|T_i=0] = E[Y_i|T_i=1] - E[Y_i|T_i=0]\\)</p> <p>Approach 2: Conditional Average Treatment Effect - used when we expect that the treatment assignment is confounded by pre-treatment covariates \\(X\\) - this is commonly seen in observed data - we assume that \\((Y_0, Y_1) \\bot T | X\\) - controlling for X is enough if treatment is as good as random conditional on \\(X\\) - this is also known as unconfoundedness - this means that the ATE is calculated as \\(E[Y_i(1) - Y_i(0)] =E[Y_i(1)-Y_i(0)|X] = E[E[Y_i|X_i, T_i=1] - E[Y_i|X_i, T_i=0]\\) - note that \\(\\text{CATE}\\) and individual treatment effect can be considered the same</p>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#choice-of-estimator","title":"Choice of Estimator","text":"<p>A good estimator is: - Unbiased - Consistent - Efficient - Robust</p>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#example","title":"Example","text":"<pre><code>graph LR\n    cx[&lt;b&gt;Alice&lt;/b&gt;&lt;br&gt;Age: 25&lt;br&gt;Cohort Age: 5&lt;br&gt;Region: City&lt;br&gt;Device: iOS] --&gt; t0[T=0&lt;br&gt;Promotion]\n    cx --&gt; t1[T=1&lt;br&gt;No promotion]\n    t0 --&gt; o1[\"LTV=?&lt;br&gt;Y(0)\"]\n    t1 --&gt; o2[\"LTV=?&lt;br&gt;Y(1)\"]\n    style cx text-align: left\n    style t0 text-align: left\n    style t1 text-align: left\n    style o1 text-align: left</code></pre> X (age, cohort_age, region, device) Promo (Y1) No Promo (Y0) Observed Y CATE (25, 5, city, iOS) 60 55 60 5 (35, 1, suburb, iOS) 70 65 65 5 (25, 5, city, android) 70 60 70 10 (27, 0, city, iOS) 90 80 80 10 (36, 2, city, android) 85 80 80 5 (17, 2, suburb, iOS) 75 70 75 5 (21, 7, suburb, iOS) 100 90 90 10 (36, 2, city, android) 80 70 80 10 E(Y) 71.25 78.75 7.5 ATE 7.5 <p>The bold values represent actual observed outcomes.</p> <p>If we assumed RCT then ATE = -7.5 = E[Y|T=1] - E[Y|T=0].</p> <p>However in this case we can see that the actual treatment effect is 7.5 - and a perfect CATE strategy would estimate that.</p>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#assumptions","title":"Assumptions","text":""},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#ignorability","title":"Ignorability","text":"<p>Basically we are saying that we control for everything possible to make sure our treatment assignment is not biased.</p> <ol> <li>The causal structure when treatment assignment mechanism is ignorable - i.e. not    arrow from X to T - no confounding <pre><code>graph LR\n  T ---&gt; Y\n  X ---&gt; Y</code></pre></li> <li>Causal structure of X confounding the effect of T on Y. The confounding is depicted    as the red dashed line. <pre><code>graph LR\n  T --&gt; Y\n  X --&gt; T\n  X --&gt; Y</code></pre></li> </ol>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#positivity-aka-overlap","title":"Positivity (a.k.a Overlap)","text":"<p>Two ways to look at positivity a.k.a overlap:</p> <ol> <li>For all values of covariates \\(x\\) present in the population of subjects, \\(0 &lt; P(T=1|X=x) &lt; 1\\). That is the probability of treatment assignment for all values of covariate \\(x\\) should be non-zero.</li> <li>As overlap between the conditional distributions \\(P(X|T=0)\\) and \\(P(X|T=1)\\) is present. </li> </ol> <p>An example is:</p> <ul> <li>Data on previous promos were only applied to Cx that are more than 2 years since activation. </li> <li>This means you can\u2019t estimate reliably the outcome under T = 1 for Cx with &lt; 2 cohort age.</li> </ul>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#the-positivity-unconfoundedness-tradeoff","title":"The Positivity - Unconfoundedness Tradeoff","text":"<p>Similar to curse of dimensionality, as you increase the number of covariates you condition on the degree of overlap decreases. </p> <p>Therefore even if you can guarantee ignorability by controling for many confounders, you may still have a problem with overlap or positivity.</p>"},{"location":"Technical/Experimentation/Outline/","title":"Outline","text":"<p>Causal Inference</p> <ul> <li>Bayesian vs. Frequentist</li> </ul> <p>Basic Probability and Statistics</p> <ul> <li>Probability Theory</li> <li>Potential Outcomes Framework</li> <li>Graphical Models</li> <li>False Positives and False Negatives</li> <li>P-Values</li> <li>Power</li> <li>Confidence Interval</li> <li>CTR Variance</li> </ul> <p>Designing Experiments</p> <ul> <li>Why experiment?</li> <li>Landscape</li> <li>Product Development Cycle</li> <li>Measuring Impact</li> <li>What does the data look like</li> <li>How to randomize</li> <li>What could go wrong</li> <li>What to measure</li> <li>How to measure</li> <li>Compare</li> <li>Design and Monitor</li> <li>Interpret and Recommend Action</li> <li>A/A Test</li> </ul> <p>Overall Evaluation Criteria (OEC)</p> <p>Multiple Testing</p> <ul> <li>False Positives and Multiple Testing</li> <li>Omnibus test</li> </ul> <p>Tiered Metrics</p> <p>Central Limit Theorem and Handling Violated Assumptions</p> <ul> <li>When not to A/B Test</li> <li>What to do when you cannot A/B test</li> <li>How to check assumptions</li> <li>Bootstrap and Delta Method</li> <li>One-sided and Two Sided tests</li> <li>High Skew Remedies</li> <li>Small Samples</li> <li>Data Quality Checks</li> </ul> <p>Sequential Tests &amp; Variance Reduction</p> <ul> <li>Peeking and Sequential Testing</li> <li>Getting Results Faster</li> <li>Variance Reduction</li> <li>CUPED (vs Normal AB) and Crossover</li> <li>Fast Surrogates</li> <li>Pre-experiment Imbalance</li> </ul> <p>Multi-armed Bandits</p> <ul> <li>vs. AB</li> <li>vs. Contextual Bandits</li> </ul> <p>Marketplace and Network Effects</p>"}]}