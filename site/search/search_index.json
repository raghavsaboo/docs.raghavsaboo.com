{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to my digital brain dump! \ud83e\udde0\ud83d\udca1 Dive into evolving notes on various topics\u2014it's a dynamic space where knowledge is always in motion. Feel free to contribute and learn with me! \ud83d\ude80</p>"},{"location":"Non-Technical/Areas%20of%20Interest/","title":"Areas of Interest","text":"<ul> <li>Story Telling</li> <li>Writing</li> <li>Spoken Delivery</li> <li>Psychology</li> <li>Business</li> </ul>"},{"location":"Non-Technical/Business/Books/The%20Personal%20MBA%20by%20Josh%20Kaufman/","title":"The Personal MBA by Rory Sutherland","text":"<p>Link: The Personal MBA</p>"},{"location":"Non-Technical/Business/Books/The%20Personal%20MBA%20by%20Josh%20Kaufman/#value-creation","title":"Value Creation","text":"<p>The key to value creation is to link a repeatable process that combines</p> <ol> <li>Value Creation - actually discovering and building something that people want</li> <li>Marketing - driving attention to it</li> <li>Sales - convert interest into paying customers</li> <li>Value Delivery - ensure customers are satisfied with what you promised</li> <li>Finance - sustain the process throug profit</li> </ol> <p>with the needs of the market which can fall into one of the following human drives</p> <ol> <li>The Drive to Acquire</li> <li>The Drive to Bond</li> <li>The Drive to Learn</li> <li>The Drive to Defend</li> <li>The Drive to Feel</li> </ol>"},{"location":"Non-Technical/Psychology/Books/Alchemy%3A%20The%20Dark%20Art%20and%20Curious%20Science%20of%20Creating%20Magin%20in%20Brands%2C%20Business%2C%20and%20Life/","title":"Alchemy by Rory Sutherland","text":"<p>Link: Good Reads</p>"},{"location":"Non-Technical/Psychology/Books/Alchemy%3A%20The%20Dark%20Art%20and%20Curious%20Science%20of%20Creating%20Magin%20in%20Brands%2C%20Business%2C%20and%20Life/#overview","title":"Overview","text":"<p>The main premise of the book is that while science and logic has resulted in immensely valuable products, there is a treasure trove still waiting to be discovered by applying apparently illogical solutions to human problems.</p> <ul> <li>Just because the scientific methodology has been so reliable it does not have to be the only tool to apply especially   to a messy field like human behaviour.</li> <li>\"Engineering does not allow for magic. Psychology does.\"</li> <li>Rory defines the way humans make decisions as \"psycho-logic\" - to distinguish it from the concepts of \"logic\" and \"   rationality\"</li> <li>The idea is to become adept at spotting instances where the \"universal laws\" don't apply - when abandoning logic is   sensible</li> </ul> <p>A 4x4 matrix that can be plotted of human advances / ideas that fall on a spectrum between FAILS to WORKS and SEEMS WEIRD to MAKES SENSE.</p> <p>e.g. Bicycles definitely work but are at the same time very weird - humans have learned how to ride bicycles but it is not built in a \"logical\" manner.</p>"},{"location":"Non-Technical/Psychology/Books/Alchemy%3A%20The%20Dark%20Art%20and%20Curious%20Science%20of%20Creating%20Magin%20in%20Brands%2C%20Business%2C%20and%20Life/#signalling","title":"Signalling","text":""},{"location":"Non-Technical/Psychology/Books/Alchemy%3A%20The%20Dark%20Art%20and%20Curious%20Science%20of%20Creating%20Magin%20in%20Brands%2C%20Business%2C%20and%20Life/#subconcious-hacking","title":"Subconcious Hacking","text":""},{"location":"Non-Technical/Psychology/Books/Alchemy%3A%20The%20Dark%20Art%20and%20Curious%20Science%20of%20Creating%20Magin%20in%20Brands%2C%20Business%2C%20and%20Life/#satisficing","title":"Satisficing","text":""},{"location":"Non-Technical/Psychology/Books/Alchemy%3A%20The%20Dark%20Art%20and%20Curious%20Science%20of%20Creating%20Magin%20in%20Brands%2C%20Business%2C%20and%20Life/#psychophysics","title":"Psychophysics","text":""},{"location":"Non-Technical/Story%20Telling/Books/Storyworthy%20by%20Matthew%20Dicks/","title":"Storyworthy by Matthew Dicks","text":"<p>Link: Matthew Dicks Official Site</p>"},{"location":"Non-Technical/Story%20Telling/Books/Storyworthy%20by%20Matthew%20Dicks/#how-to-brainstorm-story-ideas","title":"How to Brainstorm Story Ideas","text":"<ul> <li> <p>Spend 5 minutes each day to write 2-3 sentences - not the entire story - of moments from the day</p> </li> <li> <p>Don't worry of connecting threads of stories from previous days</p> </li> <li> </li> <li> <p>Spend 10 minutes to allow yourself to write your stream of conciousness/thoughts</p> </li> <li>Don't let your pen from stopping - let new ideas keep crashing in without hesitation or judgement</li> <li> <p>Be willing to leave a good idea behind in favour of a new one - even if the new idea is bad</p> </li> <li> </li> <li> <p>A story against each of these prompts e.g. <code>First/Best/Last/Worst Car</code></p> </li> <li>Annotate any as potential story or anecdote</li> <li>But not all listed will be story worthy</li> </ul>"},{"location":"Non-Technical/Story%20Telling/Books/Storyworthy%20by%20Matthew%20Dicks/#homework-for-life","title":"Homework for Life","text":""},{"location":"Non-Technical/Story%20Telling/Books/Storyworthy%20by%20Matthew%20Dicks/#crash-burn","title":"Crash &amp; Burn","text":""},{"location":"Non-Technical/Story%20Telling/Books/Storyworthy%20by%20Matthew%20Dicks/#first-best-last-worst","title":"First, Best, Last, Worst","text":""},{"location":"Technical/Areas%20of%20Interest/","title":"Areas of Interest","text":"<p>Below are the key areas of technical notes</p> <ul> <li>Algorithms</li> <li>Data Structures</li> <li>Statistics</li> <li>Linear Algebra</li> <li>Calculus</li> <li>Machine Learning</li> <li>Distributed Systems Design</li> </ul>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/arrays/","title":"Arrays","text":"<p>Python has various \"sequence\" classes, namely the built in list, tuple and str classes. They have significant commonality, most notably that:</p> <ol> <li>each supports indexing to access an individual elements of a sequence using a syntax such as <code>seq[k]</code></li> <li>each uses a low-level concept known as an array to represent the sequence</li> </ol> <p>However they also have significant differences in the abstractions that these classes represent, and in the way instances of these classes are represented internally by Python.</p>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/arrays/#low-level-arrays","title":"Low-Level Arrays","text":"<p>The primary memory of a computer is composed of bits of information, and those bits are typically grouped into larger units that depend upon the precise system architecture. Such a typical unit is a byte, which is equivalent to 8 bits.</p> <p>To keep track of what information is stored in what byte, the computer uses an abstraction known as a memory address - each byte of memory is associated wih a unique number that serves as its address (more formally, the binary representation of the number servers as the address).</p> <p>Even thought the bytes are physically stored sequentially, Random Access Memory can store and retrieve in <code>O(1)</code> time.</p> <p>A group of related variables can be stored one after another in a contiguous portion of the computer's memory - denoted as an array. An example is a text string where each character is represented using the Unicode Character set with 16 bits (i.e. 2 bytes) for each character. So a siz-character string, such as 'SAMPLE' is stored in 12 consecutive bytes of memory.</p> <p>Hence each cell of an array must use the same number of bytes to allow an arbitrary cell of the array to be accessed in constant time based on its index.</p>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/arrays/#referential-arrays","title":"Referential Arrays","text":"<p>Imagine an array of 200 strings - these strings can be of any length. So one way to store this would be to reserve enough space for each cell to hold the maximum length string but that would be wasteful. So instead we store the reference of each cell's object - i.e. memory addresses at which the elements of the sequence reside.</p> <p>In such a scenario:</p> <ol> <li>a single list may include multiple references to the same object as elements of the list</li> <li>it is possible for a single object to be an element of two or more lists</li> </ol> <p>When elements are immutable, this is not a huge issue, as neither of the lists can cause a change to the shared object. e.g. <code>temp[2] = 15</code> just changes the reference of the indexed cell to the new object <code>15</code>.</p> <p>More care is needed when we are dealing with mutable objects.</p>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/arrays/#compact-array","title":"Compact Array","text":"<p>Strings are for example represented using an array of characters (not an array of references) - i.e. a compact array because the array is storing the bits that represent the primary data.</p> <p>These have some advantages over referential structures in terms of computing performance:</p> <ol> <li>overall memory usage will be much lower for a compact structure because there is no overhead devoted to the explicit storage of the sequence of memory references in addition to the primary data</li> <li>the primary data are stored consecutively in memory - which is not the case for a referential structure. Because of the workings of the cache and memory hierarchies of computers, it is often advantageous to have data stored in memory near other data that might be used in the same computations.</li> </ol> <p>Primary support for compact arrays is in a module named <code>array</code>.</p>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/arrays/#dynamic-arrays-and-amortization","title":"Dynamic Arrays and Amortization","text":"<p>When creating a low-level array in a computer system, the precise size of that array must be explicitly declared in order for the system o properly allocate a consecutive piece of memory for its storage. Because the system may dedicate neighboring memory locations to store other data, the capacity of an array cannot trivially be increased by expanding into subsequent cells.</p> <ul> <li>for <code>tuple</code> or <code>str</code> this is not a problem - they are immutable, so the correct size for an underlying array can be fixed when the object is instantiated</li> </ul> <p>However <code>list</code> class allows us to add elements tot he list with no apparent limit to the overall capacity of the list - this is accomplished through an algorithmic implementation of a dynamic array.</p> <p>The key properties that allow this are:</p> <ol> <li>the list instance maintains an underlying array that is often larger / has greater capacity than the current length of the list - the system may reserve an underlying array capable of storing more object references than what the list was instantiated with</li> <li>as new elements are appended to a list, the class requests new larger arrays from the system and initialize the new array so that its prefix matches that of the existing small array - at which point the old array is reclaimed by the system</li> </ol>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/arrays/#implementing-a-dynamic-array","title":"Implementing a Dynamic Array","text":"<pre><code>import ctypes\n\nclass DynamicArray:\n    \"\"\"\n    A dynamic array class akin to a simplified Python list.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Create an empty array\"\"\"\n        # count actual elements\n        self._n = 0\n        # default array capacity\n        self._capacity = 1\n        # low-level array\n        self._A = self._make_array(self._capacity)\n\n    def __len__(self):\n        \"\"\"Return number of elements stored in the array.\"\"\"\n        return self._n\n\n    def __get_item(self, k):\n        \"\"\"Return element at index k.\"\"\"\n        if not 0 &lt;= k &lt; self._n:\n            raise IndexError('invalid index')\n        # retrieve from array\n        return self._A[k]\n\n    def append(self, obj):\n        \"\"\"Add an object to the end of the array\"\"\"\n\n        # if there is not enough room\n        if self._n == self._capacity:\n            # double the capacity\n            self._resize(2 * self._capacity)\n\n        self._A[self._n] = obj\n        self._n += 1\n\n    def insert(self, k, obj):\n        \"\"\"Insert value at index k, shifting subsequent values rightward\"\"\"\n\n        # we assume that k is 0 &lt;= k &lt;= n\n        if self._n == self._capacity:\n            # not enough room\n            self._resize(2 * self._capacity)\n\n        for j in range(self._n, k, -1):\n            # shift rightmost first\n            self._A[j] = self._A[j-1]\n\n        # store newest element\n        self._A[k] = obj\n        self._n += 1\n\n    def remove(self, k, obj):\n        \"\"\"Remove value at index k, shifting subsequent values leftward\"\"\"\n\n        # we don't consider shrinking the dynamic array in this implementation\n        for k in range(self._n):\n            if self._A[k] == obj:\n                # found the object\n                for j in range(k, self._n - 1):\n                    # shift other values to fill the gap\n                    self._A[j] = self._A[j+1]\n                # garbage collection\n                self._A[self._n - 1] = None\n                # have one less item\n                self._n -= 1\n                return\n\n        raise ValueError('object / value not found')\n\n\n    def _resize(self, c):\n        \"\"\"Resize internal array to capacity c\"\"\"\n\n        # create new array\n        B = self._make_array(c)\n\n        # copy all existing values to new array\n        for k in range(self._n):\n            B[k] = self._A[k]\n\n        self._A = B\n        self._capacity = c\n\n    def _make_array(self, c):\n        \"\"\"Return new array with capacity c\"\"\"\n\n        return (c * ctypes.py_object)()\n</code></pre>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/arrays/#amortized-analysis-of-dynamic-arrays","title":"Amortized Analysis of Dynamic Arrays","text":"<p>It may seem that replacing an array with a new larger array might seem slow (because a single append operation may require O(n) time to perform), however notice that by doubling the capacity during an array replacement the new array allows us to add <code>n</code> new elements before the array must be replaced again.</p> <p>Therefore performing a series of operations on an initially empty dynamic array is efficient in terms of its total running time (or amortized time).</p> <p>So the amortized bound of appending items to a list can be shown to be <code>O(1)</code> - and this is also true for any geometrically increasing progression of array sizes.</p> <p>But arithmetic progression (i.e. a constant increase in cells of a dynamic array) does not perform as well - in fact it causes the append operation to be quadratic to the number of operations.</p> <p>Also geometric increase in capacity for dynamic arrays guarantees that the final array size is proportional to the overall number of elements - i.e. the data structure uses O(n) memory. However some considerations need to be made if repeated insertions and removals from the array are possible.</p>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/arrays/#efficiencies","title":"Efficiencies","text":"<p>Space Complexity: <code>O(n)</code></p> <p>Time Complexities:</p> <p></p>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/arrays/#pythonic-code-notes","title":"Pythonic Code Notes","text":"<ol> <li> <p>Extending a list - use <code>extend</code> instead of <code>append</code> when adding multiple new entries in an array. This is because <code>extend</code> will pre-compute the amount of resizing needed for the new data in advance.</p> </li> <li> <p>Constructing new lists - use list comprehensions instead of <code>append</code> - again due to similar reasons as above. However be careful in how the objects are referenced:</p> </li> </ol> <pre><code># this will create a reference to the same [0, 0] list!\nincorrect_2d_array = [[0] * 2] * 5\n# this will create reference to independent [0, 0] lists\ncorrect_2d_array = [[0] * 2 for j in range(5)]\n\nincorrect_2d_array[0][0] = 100\ncorrect_2d_array[0][0] = 100\n\nprint(f\"Incorrect 2D array: {incorrect_2d_array}\")\nprint(f\"Correct 2D array: {correct_2d_array}\")\n</code></pre> <pre><code>Incorrect 2D array: [[100, 0], [100, 0], [100, 0], [100, 0], [100, 0]]\nCorrect 2D array: [[100, 0], [0, 0], [0, 0], [0, 0], [0, 0]]\n</code></pre>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/double-ended%20queues/","title":"Dequeue - Double-Ended Queues","text":"<p>A queue like data structure that supports insertion and deletion from both the front and back of the queue.</p> <p>An implementation of this is available through the <code>deque</code> class in Python in the standard collections module.</p>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/double-ended%20queues/#array-based-deqeue-implementation","title":"Array-Based Deqeue Implementation","text":"<p>We can implement a deque in a similar way as the Queue. The main modifications are:</p> <ol> <li>adding a pointer to the last element as <code>.last()</code> where <code>last = (self._front + self._size - 1) % len(self._data)</code></li> <li>ability to add and remove from the back of the queue</li> </ol> <pre><code>class Empty(Exception):\n    \"\"\"Error attempting to access an element from an empty container.\"\"\"\n    pass\n\nclass ArrayQueue:\n    \"\"\"FIFO queue implementation using list\"\"\"\n\n    DEFAULT_CAPACITY = 10\n\n    def __init__(self):\n        self._data = [None] * ArrayQueue.DEFAULT_CAPACITY\n        self._size = 0\n        self._front = 0\n\n    def __len__(self):\n        return self._size\n\n    def is_empty(self):\n        return self._size == 0\n\n    def first(self):\n        if self.is_empty():\n            raise Empty('Queue is Empty')\n\n        return self._data[self._front]\n\n    def last(self):\n        if self.is_empty():\n            raise Empty('Queue is Empty')\n\n        back = (self._front + self._size - 1) % len(self._data)\n\n        return back\n\n    def add_first(self, e):\n        if self._size == len(self._data):\n            self._resize(2 * len(self.data))\n\n        self._front = (self._front - 1) % len(self._data)\n        self._data[self._front] = e\n        self._size += 1\n\n    def delete_first(self):\n        if self.is_empty():\n            raise Empty('Deque is Empty')\n\n        answer = self._data[self._front]\n\n        self._data[self._front] = None\n        self._front = (self._front + 1) % len(self._data)\n        self._size -= 1\n\n        if 0 &lt; self._size &lt; len(self._data) // 4:\n            self._resize(len(self._data) // 2)\n\n        return answer\n\n    def add_last(self, e):\n        if self._size == len(self._data):\n            self._resize(2 * len(self.data))\n\n        avail = (self._front + self._size) % len(self._data)\n        self._data[avail] = e\n        self._size += 1\n\n    def delete_last(self):\n        if self.is_empty():\n            raise Empty('Deque is empty')\n\n        back = self.last()\n        answer = self._data[back]\n        self._data[back] = None\n        self._size -= 1\n\n        if 0 &lt; self._size &lt; len(self._data) // 4:\n            self._resize(len(self._data) // 2)\n\n        return answer\n\n    def _resize(self, cap):\n        old = self._data\n        self._data = [None] * cap\n        walk = self._front\n\n        for k in range(self._size):\n            self._data[k] = old[walk]\n            walk = (1 + walk) % len(old)\n\n        self._front = 0\n</code></pre>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/double-ended%20queues/#efficiencies","title":"Efficiencies","text":"<p>Space Complexity: <code>O(n)</code></p> <p>Time Complexities:</p> <p></p>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/linked%20lists/","title":"Linked Lists","text":"<p>There are some notable disadvantages of dynamic arrays like <code>list</code> in Python</p> <ol> <li>the length of the dynamic array might be longer than the actual number of elements it stores</li> <li>amortized bounds for operations may be unacceptable in real-time systems</li> <li>insertions and deletions at interior positions of an array are expensive</li> </ol> <p>Linked lists provide an alternative to array-based ordered sequences.</p> <p>While an array provides more centralized representation with one large chunk of memory capable of accommodating references to many elements, a linked list relies on a distributed representation using a lightweight object called a node for each element.</p> <p>Each node maintains a reference to its element and one or more references to neighboring nodes in order to collectively represent the linear order of the sequence.</p>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/linked%20lists/#trade-offs-between-linked-lists-and-arrays","title":"Trade-offs between Linked Lists and Arrays","text":""},{"location":"Technical/Algorithms%20and%20Data%20Structures/linked%20lists/#advantages-of-array-based-sequences","title":"Advantages of Array-Based Sequences","text":"<ol> <li>Arrays provide <code>O(1)</code> time access to an element based on an integer index. Linked lists requires <code>O(k)</code> time to traverse the list from the beginning or possibly end of a doubly linked list.</li> <li>Operations with equivalent asymptotic bounds typically run a constant factor more efficiently with an array-based structure versus a linked structure. For example appending a new element to a linked list requires instantiation of a node, appropriate linking of nodes, and an increment of an integer. While this operation completes in <code>O(1)</code> time the actual number of CPU operations will be more in the linked version.</li> <li>Array based representations typically use proportionally less memory than linked structures. A dynamic array may be, in the worst case, allocated memory for 2n object references. With linked lists however the memory must be devoted not only to store a reference to each contained object, but also explicit references that link the nodes. So a singly linked list of length n already requires 2n references, and a doubly linked list 3n references.</li> </ol>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/linked%20lists/#advantages-of-link-based-sequences","title":"Advantages of Link-based sequences","text":"<ol> <li>Link based structures provide worst-case time bounds for their operations. This is in contrast to amortized bounds associated with the expansion and contraction of a dynamic array. In real-time systems designed for more immediate responses, a long delay caused a single (amortized) operation may have an adverse effect. Worst-case bound gives a guarantee on the sum of the time spent on the individual operations.</li> <li>Link based structures support <code>O(1)</code> time insertions and deletions at arbitrary positions. This is perhaps the biggest advantage of linked lists.</li> </ol>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/linked%20lists/#singly-linked-list","title":"Singly Linked List","text":"<p>A collection of nodes that collectively form a linear sequence. Each node stores a reference to an object that is an element of the sequence, as well as a reference to the next node of the list.</p> <p>Each node is represented as a unique object, with that instance storing a reference to its element and a reference to the next node (or <code>None</code>). The linked list must keep a reference to the head of the list - without an explicit reference to the head, there would be no way to locate that node.</p> <p>Unfortunately we cannot easily delete the last node of a singly linke list. The oly way to access the node before the last is to start from the head of the list - which is inefficient. To make this efficient we will need a <code>doubly linked</code> list.</p> <pre><code>class LinkedNode:\n    __slots__ = '_element', '_next'\n\n    def __init__(self, element, next):\n        self._element = element\n        self._next = next\n\nclass LinkedList:\n\n    def __init__(self, head, tail):\n        self._head = head\n        self._tail = tail\n        self._size = size\n\n    def add_first(self, element):\n        node = LinkedNode(element, self._head)\n        self._head = node\n        self._size += 1\n\n    def add_last(self, element):\n        node = LinkedNode(element, None)\n        self._tail._next = node\n        self._tail = node\n        self._size += 1\n\n    def remove_first(self):\n        head = self._head\n        self._head = self._head._next\n        self._size -= 1\n</code></pre>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/linked%20lists/#efficiencies","title":"Efficiencies","text":"<p>Space Complexity: <code>O(n)</code></p> <p>Time Complexities:</p> <p></p>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/linked%20lists/#stack-using-a-singly-linked-list","title":"Stack using a Singly Linked List","text":"<p>Using a singly linked list, we implement a stack. Since for a linked list we can insert and delete elements in constant time only at the head, we will use the head as the <code>top</code> of the stack.</p> <p>When implementing the node we also intentionally define <code>__slots__</code> to streamline the memory usage as there may potentially be many node instances in a single list.</p> <pre><code>class _Node:\n    __slots__ = '_element', '_next'\n\n    def __init__(self, element, next):\n        self._element = element\n        self._next = next\n\n\nclass LinkedStack:\n\n    def __init__(self):\n        self._head = None\n        self._size = 0\n\n    def __len__(self):\n        return self._size\n\n    def is_empty(self):\n        return self._size == 0\n\n    def push(self, e):\n        self._head = self._Node(e, self._head)\n        self._size += 1\n\n    def top(self):\n        if self.is_empty():\n            raise Empty('Stack is Empty')\n        return self._head._element\n\n    def pop(self):\n        if self.is_empty():\n            raise Empty('Stack is Empty')\n\n        answer = self._head._element\n\n        self._head = self._head._next\n        self._size -= 1\n        return answer\n</code></pre>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/linked%20lists/#queue-using-a-singly-linked-list","title":"Queue using a Singly Linked List","text":"<pre><code>class _Node:\n    __slots__ = '_element', '_next'\n\n    def __init__(self, element, next):\n        self._element = element\n        self._next = next\n\n\nclass LinkedQueue:\n\n    def __init__(self):\n        self._head = None\n        self._tail = None\n        self._size = 0\n\n    def __len__(self):\n        return self._size\n\n    def is_empty(self):\n        return self._size == 0\n\n    def first(self):\n        if self.is_empty():\n            raise Empty('Queue is empty')\n        return self._head._element\n\n    def dequeue(self):\n        if self.is_empty():\n            raise Empty('Queue is empty')\n\n        answer = self._head._element\n        self._head = self._head._next\n        self._size -= 1\n        if self.is_empty():\n            self._tail = None\n\n        return answer\n\n    def enqueue(self, element):\n        newest = self._Node(element, None)\n        if self.is_empty():\n            self._head = newest\n        else:\n            self._tail._next = newest\n        self._tail = newest\n        self._size += 1\n</code></pre>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/linked%20lists/#circularly-linked-lists","title":"Circularly Linked Lists","text":"<p>Case where the <code>next</code> reference of the tail of the list circularly points back to the head of the list.</p>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/queues/","title":"Queues","text":"<p>A <code>queue</code> is a collection of objects that are inserted and removed according to the <code>first-in, first-out (FIFO)</code> principle. Elements can be inserted at any time, but only the elements that has been in the queue the longest can be next removed.</p> <p>Some common methods supported by a queue are:</p> <ul> <li><code>queue.enqueue(e)</code> - add an element <code>e</code> to the back of a queue</li> <li><code>queue.dequeue()</code> - remove and return the first element from a stack</li> <li><code>queue.first()</code> - return the first element of a stack</li> <li><code>queue.is_empty()</code> - check if queue is empty</li> <li><code>len(queue)</code> - the number of elements in a queue</li> </ul>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/queues/#array-based-queue-implementation","title":"Array-Based Queue Implementation","text":"<p>Utilizing a <code>list</code> for a queue would be very inefficient - this is because <code>pop(0)</code> i.e. a <code>pop</code> on a non-default index causes a loop to be executed that shifts all elements beyon the index to te left. This would cause the worst-case behavior of O(n) time.</p> <p>Therefore we need to implement a queue using a circular array with the following logic:</p> <ol> <li>initialize a <code>list</code> with a fixed size that is larger than the actual number of elements t be ever added tot he queue</li> <li>define <code>front</code> as the index of the \"first\" element of a queue</li> <li>enqueue items to the index calculated by <code>(front + size) % capacity</code> of the queue</li> <li>for example for a queue of size 3, enqueue of [2, 1, 4] would be built as following: [2, None, None] -&gt; [2, 1, None] -&gt; [2, 1, 4]</li> <li>then following dequeue operations will happen like so: [None, 1, 4] and front = 1 -&gt; [None, None, 4] and front = 2 etc.</li> <li>whenever the size of the queue is equal to its capacity, resize it to be double the capacity, and whenever the size is \u00bcth of the capacity, resize it to be half the capacity</li> </ol> <pre><code>class Empty(Exception):\n    \"\"\"Error attempting to access an element from an empty container.\"\"\"\n    pass\n\nclass ArrayQueue:\n    \"\"\"FIFO queue implementation using list\"\"\"\n\n    DEFAULT_CAPACITY = 10\n\n    def __init__(self):\n        self._data = [None] * ArrayQueue.DEFAULT_CAPACITY\n        self._size = 0\n        self._front = 0\n\n    def __len__(self):\n        return self._size\n\n    def is_empty(self):\n        return self._size == 0\n\n    def first(self):\n        if self.is_empty():\n            raise Empty('Queue is Empty')\n\n        return self._data[self._front]\n\n    def dequeue(self):\n        if self._is_empty():\n            raise Empty('Queue is Empty')\n\n        answer = self._data[self._front]\n\n        self._data[self._front] = None\n        self._front = (self._front + 1) % len(self._data)\n        self._size -= 1\n\n        if 0 &lt; self._size &lt; len(self._data) // 4:\n            self._resize(len(self._data) // 2)\n\n        return answer\n\n    def enqueue(self, e):\n        if self._size == len(self._data):\n            self._resize(2 * len(self.data))\n\n        avail = (self._front + self._size) % len(self._data)\n        self._data[avail] = e\n        self._size += 1\n\n    def _resize(self, cap):\n        old = self._data\n        self._data = [None] * cap\n        walk = self._front\n\n        for k in range(self._size):\n            self._data[k] = old[walk]\n            walk = (1 + walk) % len(old)\n\n        self._front = 0\n</code></pre>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/queues/#efficiencies","title":"Efficiencies","text":"<p>Space Complexity: <code>O(n)</code></p> <p>Time Complexities:</p> <p></p>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/recursion/","title":"Recursion","text":"<p>Recursion is another way to achieve repetition apart from loops. In recursion a function makes one or more calls to itself during execution, or by which a data structure relies on smaller instances of the same type of structure in its representation.</p> <p>A recursive function has some basic properties:</p> <ol> <li>it contains one or more base cases which are defined non-recursively in terms of fixed quantities</li> <li>it contains one or more recursive cases which are defined by appealing to the definition of the function being defined</li> </ol> <pre><code>def factorial(n):\n\n    # base case\n    if n == 0:\n        return 1\n    else:\n        return n * factorial(n-1)\n</code></pre> <p>In Python, each time a function (recursive or otherwise) is called, a structure known as an activation record or frame is created to store information about the progress of that invocation of the function. This activation record includes a namespace for storing the function call's parameters and local variables, and information about which command in the body of the function is currently executing.</p> <p>When the execution of a function leads to a nested function call, the execution of the former call is suspended and its activation record stores the place in the source code at which the flow of control should continue upon return of the nested call. This process is used both in the standard case of one function calling a different function, or in the recursive case in which a function invokes itself. The key point is that there is a different activation record for each active cell.</p> <pre><code>import os\n\ndef disk_usage(path):\n    \"\"\"\n    Return the number of bytes used by a file/folder and any descendents.\n    \"\"\"\n    total = os.path.getsize(path)\n\n    if os.path.isdir(path):\n        for filename in os.listdir(path):\n            childpath = os.path.join(path, filename)\n            total += disk.usage(childpath)\n\n        print(f'{total}', path)\n        return total\n</code></pre>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/recursion/#maximum-recursive-depth-in-python","title":"Maximum Recursive Depth in Python","text":"<p>If each recursive call makes another recursive call, without ever reaching a base case, then we have an infinite series of such calls.</p> <p>This is called infinite recursion and it is a fatal error as it can quickly swamp computing resources, not only due to rapid use of the CPU, but because each successive call creates an activation record requiring additional memory.</p> <p>To avoid this, we should always ensure that each recursive call is in some way progressing toward a base case. Also in Python there is an intentional design decision to limit the overall number of function activations that can be simultaneously active at ~ 1,000.</p> <p>In Python this can be dynamically reconfigured:</p> <pre><code>import sys\n\nold = sys.getrecursionlimit()\nsys.setrecursionlimit(100000)\n</code></pre>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/recursion/#other-examples-of-recursion","title":"Other Examples of Recursion","text":"<ul> <li>If a recursive call starts at most one other, we call this a linear recursion</li> <li>If a recursive call may start two others, we all this a binary recursion</li> <li>If a recursive call may start three or more ohers, this is multiple recursion</li> </ul> <p>Note that the linear recursion terminology here reflects the structure of the recursion trace, and not the time complexity.</p>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/recursion/#linear-recursion-examples","title":"Linear Recursion Examples","text":""},{"location":"Technical/Algorithms%20and%20Data%20Structures/recursion/#linear-sum","title":"Linear Sum","text":"<p>Calculating the sum of a sequence of numbers by adding the last number to the sum of the first <code>n-1</code>.</p> <pre><code>def linear_sum(S, n):\n    \"\"\"Return the sum of the first n numbers of sequence S.\n    \"\"\"\n    if n == 0:\n        return 0\n    else:\n        return linear_sum(S, n-1) + S[n-1]\n</code></pre>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/recursion/#reversing-a-sequence","title":"Reversing a Sequence","text":"<p>Reversal of a sequence by swapping the first and last elements, and then recursively reversing the remaining elements.</p> <pre><code>def reverse(S, start, stop):\n    \"\"\"Reverse elements in implicit slice S[start:stop]\n    \"\"\"\n    if start &lt; stop - 1:\n        S[start], S[stop-1] = S[stop-1], S[start]\n        reverse(S, start+1, stop-1)\n</code></pre>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/recursion/#computing-powers","title":"Computing Powers","text":"<p>Raising a number \\(x\\) to an arbitrary non-negaive integer, \\(n\\) - i.e. compute the power function, defined as \\(\\text{power}(x,n)=x^n\\).</p> <p>A trivial definition would follow from the fact that \\(x^n=x \\cdot x^{n-1}\\)</p> \\[ \\text{power}(x,n)=     \\begin{cases}     1 &amp; \\text{if n=0} \\\\     x \\cdot \\text{power}(x, n-1) &amp; \\text{otherwise}     \\end{cases} \\] <p>This is <code>O(n)</code></p> <p>A much faster way to compute the power function is the squaring technique. Let \\(k=\\lfloor \\frac{n}{2} \\rfloor\\) denote the floor of the division. When \\(n\\) is even, \\(k=\\lfloor \\frac{n}{2} \\rfloor=\\frac{n}{2}\\) and therefore \\((x^k)^2=(x^{\\frac{n}{2}})^2=x^n\\). When \\(n\\) is odd \\(k=\\lfloor \\frac{n}{2} \\rfloor=\\frac{n-1}{2}\\) and therefore \\((x^k)^2=(x^{\\frac{n-1}{2}})^2=x^{n-1}\\).</p> \\[ \\text{power}(x,n)=     \\begin{cases}     1 &amp; \\text{if n=0} \\\\     x \\cdot (\\text{power}(x, \\lfloor \\frac{n}{2} \\rfloor))^2 &amp; \\text{if n&gt;0 is odd} \\\\     \\text{power}(x, \\lfloor \\frac{n}{2} \\rfloor)^2 &amp; \\text{if n&gt;0 is even} \\\\     \\end{cases} \\] <p>This is <code>O(log n)</code></p> <pre><code>def power(x, n):\n    \"\"\"Compute the value x**n for integer n.\"\"\"\n    if n == 0:\n        return 1\n    else:\n        return x*power(x, n-1)\n\ndef faster_power(x, n):\n    \"\"\"Compute the value x**n for integer n.\"\"\"\n    if n == 0:\n        return 1\n    else:\n        partial = power(x, n//2)\n        result = partial * partial\n        if n % 2 == 1:\n            result *= x\n        return result\n</code></pre>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/recursion/#binary-recursion","title":"Binary Recursion","text":""},{"location":"Technical/Algorithms%20and%20Data%20Structures/recursion/#binary-sum","title":"Binary Sum","text":"<p>Summing the \\(n\\) elements of a sequence, \\(S\\), of numbers by computing the sum of the first half and the sum of the second half, and then adding them together.</p> <pre><code>def binary_sum(S, start, stop):\n    \"\"\"Return the sum of the numbers in implicit slic S[start:stop]\"\"\"\n    if start &gt;= stop:\n        return 0\n    elif start == stop - 1:\n        return S[start]\n    else:\n        mid = (start + stop) // 2\n        return binary_sum(S, start, mid) + binary_sum(S, mid, stop)\n</code></pre>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/recursion/#multiple-recursion","title":"Multiple Recursion","text":""},{"location":"Technical/Algorithms%20and%20Data%20Structures/recursion/#summation-puzzle","title":"Summation Puzzle","text":"<p>A common example is when we want to enumerate various configurations in order to solve a combinatorial puzzle e.g. a summation puzzle.</p> \\[ \\begin{split} pot + pan = bib \\\\ dog + cat = pig \\\\ boy + girl = baby \\end{split} \\] <p>Here we need to assign a unique digit (0...9) to each letter in the equation in order to make the equation true. So we can use the computer to enumerate all possibilities and test each one.</p> <p>The general algorithm for building sequences is:</p> <ol> <li>Recursively generate the sequences of <code>k - 1</code> elements</li> <li>Append to each such sequence an element not already contained in it</li> <li>Use a set <code>U</code> to keep track of the elements not contained in the current sequence, so that na element <code>e</code> is considered to not have been used yet if and only if <code>e</code> is in <code>U</code></li> </ol> <pre><code>puzzle_solve(k, S, U):\n    Input: An integer k, sequence S, and set U\n    Output: enumeration of all k-length extensions to S using elements in U without repetitions\n\n    for each e in U do\n        Add e to the end of S\n        Remove e from U\n        if k==1 then\n            Test whether S is a configuration that solves the puzzle\n            if S solves the puzzle then\n                return \"Solution found: \" S\n        else\n            puzzle_solve(k-1, S, U)\n        Remove r from the end of S\n        Add e back to U\n</code></pre>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/recursion/#designing-recursive-algorithms","title":"Designing Recursive Algorithms","text":"<p>Think of the different ways to define subproblems that have the same general structure as the original problem.</p> <p>Add necessary parameterization to the function (e.g. passing beginning and end of sub-array).</p> <p>Test for base cases - there should at least be one, and defined so that every possible chain of recursive calls eventually reaches a base case.</p> <p>Recur - for non-base cases, perform one or more recursive calls.</p>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/recursion/#eliminating-tail-recursion","title":"Eliminating Tail Recursion","text":"<p>The usefulness of recursion comes at a modest cost - in particular the Python interpreter must maintain activation records that keep track of the state of each nested call.</p> <p>Some forms of recursion can be eliminated without the use of axillary memory (like stacks) - and a notable form is tail recursion.</p> <p>A recursion is a tail recursion if any recursive call is made from one context is the very last operation in that context, with the return value of the recursive call immediately returned by the enclosing recursion. In this can by necessity, a tail recursion must be a linear recursion.</p> <p>Examples are binary search and the sequence reversing algorithm.</p> <p>However the factorial function is not a tail recursion as it involves <code>return n * factorial(n-1)</code> which means an additional multiplication is performed after the recursive call.</p> <p>Tail recursions can be reimplemented non-recursively by enclosing the body in a loop for repetition, and replacing a recursive call with new parameters by reassignment of the existing parameters to those values.</p> <pre><code>def binary_search_iterative(data, target):\n    low = 0\n    high = len(data) - 1\n\n    while low &lt;= high:\n        mid = (low + high) // 2\n        if target == data[mid]:\n            return True\n\n        elif target &lt; data[mid]:\n            high = mid - 1\n\n        else:\n            low = mid + 1\n\n    return False\n\ndef reverse_iterative(S):\n\n    start, stop = 0, len(S)\n\n    while start &lt; stop - 1:\n        S[start], S[stop-1] = S[stop-1], S[start]\n        start, stop = start + 1, stop - 1\n</code></pre>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/searching/","title":"Searching","text":""},{"location":"Technical/Algorithms%20and%20Data%20Structures/searching/#binary-search","title":"Binary Search","text":"<p>A classic recursive algorithm, binary search, that is used to locate a target value within a sorted sequence of n elements.</p> <p>Time complexity: <code>O(log n)</code></p> <p>When the sequence is unsorted then we can use sequential search algorithms that run in O(n) time (i.e. linear time).</p> <pre><code>def binary_search(data, target, left, right):\n    \"\"\"\n    Return True if target is found in indicated portion of a Python list.\n\n    The search only considers the portion from data[left] to data[right] inclusive.\n    \"\"\"\n\n    if left &gt; right:\n        return False, None # interval is empty, no match\n    else:\n        mid = (left + right) // 2\n        if target == data[mid]: # found a match\n            return True, mid\n        elif target &lt; data[mid]:\n            # recur on the portion left of the middle\n            return binary_search(data, target, left, mid - 1)\n        else:\n            # recur on the portion right of the middle\n            return binary_search(data, target, mid + 1, right)\n</code></pre>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/stacks/","title":"Stacks","text":"<p>A stack is a collection of objects that are inserted and removed according to the last-in, first-out (LIFO) principle. Popular uses of stacks are for \"back\" and \"undo\" operations in browsers and editors.</p> <p>In general the LIFO protocol allows the stack to be used as a tool for reversing a data sequence, matching tags, parenthesis etc.</p> <p>Some common methods supported by a stack are:</p> <ul> <li><code>stack.push(e)</code> - add an element <code>e</code> to the top of a stack</li> <li><code>stack.pop()</code> - remove and return the top elements from a stack</li> <li><code>stack.top()</code> - return the top element of a stack</li> <li><code>stack.is_empty()</code> - check if stack is empty</li> <li><code>len(stack)</code> - the number of elements in a stack</li> </ul>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/stacks/#simple-array-based-stacks","title":"Simple Array-Based Stacks","text":"<p>We can implements stacks easily by using a <code>list</code> in Python.</p> <p>Look at Adapter Pattern to get an example of a stack implementation using lists.</p>"},{"location":"Technical/Algorithms%20and%20Data%20Structures/stacks/#efficiencies","title":"Efficiencies","text":"<p>Space Complexity: <code>O(n)</code></p> <p>Time Complexities:</p> <p></p>"},{"location":"Technical/Distributed%20Systems%20Design/Compressed%20Notes/","title":"Compressed Notes","text":""},{"location":"Technical/Distributed%20Systems%20Design/Data%20Models/","title":"Data Models","text":""},{"location":"Technical/Distributed%20Systems%20Design/Data%20Models/#overview","title":"Overview","text":"<p>Data Modeling (how data is stored) and Data Querying (how data is retrieved) choices go hand in hand.</p>"},{"location":"Technical/Distributed%20Systems%20Design/Data%20Models/#data-abstractions","title":"Data Abstractions","text":""},{"location":"Technical/Distributed%20Systems%20Design/Data%20Models/#main-categories-of-databases","title":"Main Categories of Databases","text":""},{"location":"Technical/Distributed%20Systems%20Design/Data%20Models/#1-relational-database","title":"1. Relational Database","text":"<p>When you have a relatively fixed structure and you know this structure is not going to change too rapidly.</p> <ul> <li>Optimized for Transaction and Batch Processing (Read Throughput), Joins etc.</li> <li>Data Organized as tables/relations</li> <li>Object Relational Mapping Needed</li> <li>Oracle, MySQL, PostgreSQL</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Data%20Models/#2-document-database","title":"2. Document Database","text":"<p>Target use cases are where data comes in self-constrained documents and relationships between one document and another are rare. Also the schema is easily evolved.</p> <ul> <li>NoSQL - or not only SQL</li> <li>Flexible schemas, better performance due to locality / high write throughput</li> <li>Mainly free and open source</li> <li>MongoDB, CouchDB, Espresso</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Data%20Models/#3-graph-database","title":"3. Graph Database","text":"<p>Target use cases are where anything is potentially related to everything.</p> <ul> <li>Best suited for highly interconnected data - many to many relationships</li> <li>Social graphs, web graphs etc.</li> <li>Neo4j, SPARQL, Cypher</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Overview/","title":"Overview","text":"<p>Data intensive applications are one where:</p> <ol> <li>the amount of data that is generated/uses increases quickly OR</li> <li>the complexity of data generated/used increases quickly OR</li> <li>the speed of change in data increases quickly</li> </ol>"},{"location":"Technical/Distributed%20Systems%20Design/Overview/#key-components-of-modern-data-intensive-applications","title":"Key Components of Modern Data Intensive Applications","text":"<ol> <li>Database - source of truth for any consumer.</li> <li>Cache - for temporarily storing an expensive operation to speed up reads</li> <li>Full-text index - for quickly searching data by keyword or filter</li> <li>Message queues - for message passing between processes</li> <li>Stream processing - near/realtime processing of data</li> <li>Batch processing - crunching large amounts of collected data</li> <li>Application code - logic and connective tissue between the components above</li> </ol>"},{"location":"Technical/Distributed%20Systems%20Design/Overview/#key-requirements-for-data-intensive-applications","title":"Key Requirements for Data Intensive Applications","text":""},{"location":"Technical/Distributed%20Systems%20Design/Overview/#reliability","title":"Reliability","text":"<ul> <li>Fault tolerance</li> <li>No un-authorized access</li> <li>Chaos testing</li> <li>Full machine failures</li> <li>Bugs - Automating tests</li> <li>Staging/Testing environment</li> <li>Quickly roll-back</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Overview/#scalability","title":"Scalability","text":"<ul> <li>Handle higher traffic volume</li> <li>Meeting traffic load with peak number of reads, writes and simultaneous users</li> <li>Capacity planning</li> <li>Response time vs throughput</li> <li>End user response = server response time + network response time</li> <li>90<sup>th</sup>, 95<sup>th</sup> Percentile Service Level Objectives (SLOs) / Service Level Agreements (SLAs)</li> <li>Scaling</li> <li>up (more powerful machine)</li> <li>out (distributed over many smaller machines)</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Overview/#maintainability","title":"Maintainability","text":"<ul> <li>Add new people to work</li> <li>Productivity</li> <li>Operable: Configurable and testable</li> <li>Simple: Easy to understand and ramp up</li> <li>Evolveable: Easy to change</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Partitioning/","title":"Partitioning","text":""},{"location":"Technical/Distributed%20Systems%20Design/Partitioning/#overview","title":"Overview","text":"<p>Horizontally scaling and scalability (data, users, and machines) is the key theme of partitioning.</p> <p>Partitioning == Splitting == Sharding</p>"},{"location":"Technical/Distributed%20Systems%20Design/Partitioning/#key-issues-to-look-out-for","title":"Key Issues to Look Out For","text":"<ul> <li>Hot spots / Skews</li> <li>Key Hash Based Partition</li> <li>Rebalancing strategies</li> <li>Routing Logic Placement</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Partitioning/#_1","title":"Partitioning","text":""},{"location":"Technical/Distributed%20Systems%20Design/Replication/","title":"Replication","text":""},{"location":"Technical/Distributed%20Systems%20Design/Replication/#overview","title":"Overview","text":"<p>The process of syncing data between databases in a consistent way is refered to as \"replication\".</p> <p>This is needed due to a few reasons:</p> <ul> <li>Resilience of service to Machine Failures</li> <li>Improving latency for global audience</li> <li>Scaling to millions of users</li> <li>Offline/Network failures</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Replication/#types-of-replication","title":"Types of Replication","text":""},{"location":"Technical/Distributed%20Systems%20Design/Replication/#1-single-leader","title":"1. Single Leader","text":""},{"location":"Technical/Distributed%20Systems%20Design/Replication/#2-multi-leader","title":"2. Multi-Leader","text":""},{"location":"Technical/Distributed%20Systems%20Design/Replication/#3-leaderless","title":"3. Leaderless","text":""},{"location":"Technical/Distributed%20Systems%20Design/Storage%20and%20Retrieval/","title":"Storage and Retrieval","text":""},{"location":"Technical/Distributed%20Systems%20Design/Storage%20and%20Retrieval/#which-database-to-use","title":"Which Database to Use?","text":"<ul> <li>Every storage engine is optimized for different use cases. Select the right storage   engine for your use case</li> <li>As an application developer we need to have a rough idea on what the storage engine   is doing under the hood</li> <li>Tuning and optimizing pointers</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Storage%20and%20Retrieval/#categories-of-databases","title":"Categories of Databases","text":"<p>There are two main categories of databases - OLTP (Online Transaction Processing Database) and OLAP (Online Analytical Processing Database) each with a different read pattern, write patterns, user using it, data size etc.</p> <ol> <li>OLTP - Online Transaction Processing Database optimized for latency.</li> <li>eg. MySQL</li> <li>Usually row-order store<ul> <li>easy to modify/add a record</li> <li>might read in unnecessary data</li> </ul> </li> <li>OLAP - Online Analytical Processing Databases optimized for data crunching.</li> <li>Data Warehousing (Star/Snowflake schema), column oriented</li> <li>Column compression, data cubes, optimized for reads/queries</li> <li>Materialized views, lack of flexibility</li> <li>HBase, Hive, Spark</li> <li>Usually column-order store<ul> <li>Only need to read in relevant data</li> <li>Tuple writes require multiple acesses</li> <li>Suitable for read-mostly, read-intensive, large data repositories</li> </ul> </li> </ol>"},{"location":"Technical/Distributed%20Systems%20Design/Storage%20and%20Retrieval/#database-index","title":"Database Index","text":"<ul> <li>An index is an additional structure that is derived from the primary data. A well chosen   index optimizes for reads but slows down the write.</li> <li>Simple database index is a Hash based Index. Some issues for an index:</li> <li>File format (encoding)</li> <li>Deleting records</li> <li>Crash recovery</li> <li>Partially written records</li> <li>Concurrency control</li> <li>Range queries?</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Storage%20and%20Retrieval/#types-of-storage-engines","title":"Types of Storage Engines","text":"<ul> <li>Two families of storage engines used by databases:</li> <li>Log structured - LSM-Trees e.g. SSTables -&gt; HBASE, Cassandra</li> <li>Page-Oriented - B-trees -&gt; RDBMS</li> <li>These are answers to limitations of disk access.</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Storage%20and%20Retrieval/#lsm-trees-log-sort-merge-and-sstables-sort-string-tables","title":"LSM-Trees (Log Sort Merge) and SSTables (Sort String Tables)","text":"<ul> <li>SSTables - in-memory mem table backend by Disk SSTable file, sorted by keys.</li> <li>e.g. Red-Black tree or AVL trees. Supports high write throughput.</li> <li>Lucene - full-text search is much more complex than key-value index like SSTables. However,   it does internally use SSTables for term dictionary.</li> <li>Bloom filters - memory efficient data structure used for approximating the contents   of a set. It can tell you if a key does not appear in the database, thus saves many   unnecessary disk reads for non-existent keys.</li> <li>Compaction is a background process of the means of throwing away duplicate keys in   the log and keeping only the most recent update for each key.</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Storage%20and%20Retrieval/#b-trees-index","title":"B-Trees Index","text":"<ul> <li>Most widely used indexing structure is B-Trees. One place per key!</li> <li>They are the standard implementation in RDBMS and NoSQL stores today.</li> <li>It also keeps key-value sorted by keys which allows quick lookups.</li> <li>B-Trees are designed and optimized for the hardward as disks are arranged in fixed   sized blocks, B-Trees also break down the data into fixed size 4KB blocks. There is   a root node and a branching factor (references to child pages)</li> <li>4 level tree with 4KB pages with branching factor of 500 can store up to 256TB! B-Tree   is optimized for reads!</li> <li>Write ahead log is used for crash recovery, latches for concurrency.</li> <li>Sibling references in child node allows for easier scannig of sequential keys.</li> </ul>"},{"location":"Technical/Distributed%20Systems%20Design/Storage%20and%20Retrieval/#other-indexing-concepts","title":"Other Indexing Concepts","text":"<ul> <li>Clustered index - inline storing of row values</li> <li>Secondary index - helps with joins</li> <li>Covering index - few columns are included</li> <li>Multi-column index - multiple keys concatenated</li> <li>Full-text search and fuzzy indexes help with spelling mistakes (edit distances), grammar,   synonyms, words near each other, linguistics etc.</li> <li>In Memory Stores - Redis, Memcaches etc.</li> </ul>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/","title":"Basic Probability and Statistics","text":"<p>P(A): probability of A P(A'): probability of not A (the complement) P(A, B): probability of A and B occuring together</p>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#basic-principles","title":"Basic Principles","text":"<ul> <li>P(A) &lt;= 1</li> <li>P(A') = 1 - P(A)</li> <li>P(A or B) = P(A) + P(B) - P(A and B)</li> </ul>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#conditional-probability","title":"Conditional Probability","text":"<p>P(A|B) = P(A and B) / P(B)</p> <p>Example: A: number of fatalities B: number of people whose age is between 40-49 P(A and B): number of fatalities for people whose age is between 40-49</p> <p>P(A|B) = P(A and B) / P(B)</p> <p>P(A|B) != P(A) as higher age groups tend to have higher fatality rate</p>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#independence","title":"Independence","text":"<p>If A and B are independent (not correlated) then P(A and B) = P(A)P(B) and P(A|B) = P(A)</p>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#conditional-independence","title":"Conditional Independence","text":"<p>[Typical Independence] Suppose Alice and Malice each toss separate die. A is Alice's outcome and B is Malice's outcome. Knowing Alice's outcome provides no information about Malice's outcome.</p> <p>However if Alice and Malice toss the same dice, and the dice is biased toward showing some numbers, then knowing Alice's outcome provide some information about Malice's outcome can be inferred.</p> <p>Independece does not hold A\u27c2B | C if P(A|B, C) = P(A|C)</p> <p>Given the information of C, B contributes no information about A.</p> <p>If P(C) is the distribution for outcomes for the shared dice, then B\u27c2A | C - i.e. knowing Alice's outcome A gives no additional informaiton about Malice's outcome B. Therefore P(B|(A, C)) = P(B|C).</p> <p>Another Example:</p> <pre><code>graph TD\n    A --&gt; B;\n    A --&gt; C;\n    C --&gt; E;\n    D --&gt; E;\n\n  subgraph \"Stats Knowledge\";\n    A[Statistics];\n    B[Causal Inference];\n    C[Machine Learning];\n  end\n\n  subgraph \"Job Requirement\";\n    C[Machine Learning];\n    D[SQL Skill];\n    E[Job Offer];\n  end</code></pre> <ul> <li>knowledge of statistics means you know more about causal inference and machine learning</li> <li>to get a job offer you need to know either machine learning or SQL</li> <li>B is not independent of C - if you are good at causal inference, you are probably good at statistics, and likely good at machine learning</li> <li>B is independent of C given/conditioned on A - if you know someones level of statistics, you can infer machine learning skills and knowledge of causal inference will not give any further information</li> <li>C is independent of D - knowing how good you are at machine learning tells me nothing about how good you are at SQL</li> <li>C is not conditionally independent of D given E - given you get a job offer, knowing how good you are at ML gives me an idea about your SQL skills</li> </ul>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#simpsons-paradox","title":"Simpson's Paradox","text":"<p>It can be that for all age groups, fatality rate in Italy is lower than those in China, but the overall fatality rate in Italy is higher than in China.</p> <p>This is because Age is a confounding factor - causing the Simpson Paradox. Italian population is generally older than the Chinese population.</p> <pre><code>graph LR\n    Country --&gt; Age\n    Country --&gt; Fatality\n    Age --&gt; Fatality</code></pre>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#potential-outcomes-framework","title":"Potential Outcomes Framework","text":"<p>For a set of i.i.d. subjects \\(i = 1, ..., n\\) we observe a tuple \\((X_i, Y_i, W_i)\\) comprised of:</p> <ul> <li>a feature vector \\(X_i\\)</li> <li>a response or potential outcomes \\(Y_i\\)</li> <li>a treatment assignment \\(T_i\\)</li> </ul> <p>The goal is to estimate the Causal Estimand or Causal Effect of Treatment. However we only get to observe one outcome for each \\(i\\) i.e. \\(Y_i = Y_i(T_i)\\) - you are either treated or not treated.</p> <pre><code>graph LR\n    A[Causal Estimand] --&gt; |Identificaiton| B[Statistical Estimand]\n    B[Statistical Estimand] --&gt; |Estimation| C[Estimate]</code></pre> <ul> <li>This is the \"missingness\" issue in causal inference</li> <li>Causal Estimand or Causal Effect of Treatment: \\(E[Y(1) - Y(0)]\\)</li> <li>Statistical Estimand: \\(E_X[E[Y|T=1, X] - E[Y|T=0, X]]\\)</li> <li>Estimate: \\(Average(Average(Y_i|T_i=1)) - Average(Y_i|T_i=0))\\)</li> </ul>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#average-treatment-effect-ate","title":"Average Treatment Effect - ATE","text":"<p>The causal effect of treatment is the average treatment effect i.e. \\(E[Y(1) - Y(0)]\\).</p> <p>However we cannot observe treatment and control outcomes for all subjects \\(i\\).</p> <p>Approach 1: Pure Randomized Control Trial</p> <ul> <li>we assume that \\((Y_0, Y_1) \\bot T\\)</li> <li>the potential outcomes are independent of the treatment assignment</li> <li>in an RCT we get the following: \\(E[Y_i(1)] - E[Y_i(0)] = E[Y_i(1)|T_i=1] - E[Y_i(0)|T_i=0] = E[Y_i|T_i=1] - E[Y_i|T_i=0]\\)</li> </ul> <p>Approach 2: Conditional Average Treatment Effect</p> <ul> <li>used when we expect that the treatment assignment is confounded by pre-treatment covariates \\(X\\)</li> <li>this is commonly seen in observed data</li> <li>we assume that \\((Y_0, Y_1) \\bot T | X\\)</li> <li>controlling for X is enough if treatment is as good as random conditional on \\(X\\)</li> <li>this is also known as unconfoundedness</li> <li>this means that the ATE is calculated as \\(E[Y_i(1) - Y_i(0)] =E[Y_i(1)-Y_i(0)|X] = E[E[Y_i|X_i, T_i=1] - E[Y_i|X_i, T_i=0]\\)</li> <li>note that \\(\\text{CATE}\\) and individual treatment effect can be considered the same</li> </ul>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#choice-of-estimator","title":"Choice of Estimator","text":"<p>A good estimator is:</p> <ul> <li>Unbiased</li> <li>Consistent</li> <li>Efficient</li> <li>Robust</li> </ul>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#example","title":"Example","text":"<pre><code>graph LR\n    cx[&lt;b&gt;Alice&lt;/b&gt;&lt;br&gt;Age: 25&lt;br&gt;Cohort Age: 5&lt;br&gt;Region: City&lt;br&gt;Device: iOS] --&gt; t0[T=0&lt;br&gt;Promotion]\n    cx --&gt; t1[T=1&lt;br&gt;No promotion]\n    t0 --&gt; o1[\"LTV=?&lt;br&gt;Y(0)\"]\n    t1 --&gt; o2[\"LTV=?&lt;br&gt;Y(1)\"]\n    style cx text-align: left\n    style t0 text-align: left\n    style t1 text-align: left\n    style o1 text-align: left</code></pre> X (age, cohort_age, region, device) Promo (Y1) No Promo (Y0) Observed Y CATE (25, 5, city, iOS) 60 55 60 5 (35, 1, suburb, iOS) 70 65 65 5 (25, 5, city, android) 70 60 70 10 (27, 0, city, iOS) 90 80 80 10 (36, 2, city, android) 85 80 80 5 (17, 2, suburb, iOS) 75 70 75 5 (21, 7, suburb, iOS) 100 90 90 10 (36, 2, city, android) 80 70 80 10 E(Y) 71.25 78.75 7.5 ATE 7.5 <p>The bold values represent actual observed outcomes.</p> <p>If we assumed RCT then ATE = -7.5 = E[Y|T=1] - E[Y|T=0].</p> <p>However in this case we can see that the actual treatment effect is 7.5 - and a perfect CATE strategy would estimate that.</p>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#assumptions","title":"Assumptions","text":""},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#ignorability","title":"Ignorability","text":"<p>Basically we are saying that we control for everything possible to make sure our treatment assignment is not biased.</p> <ol> <li>The causal structure when treatment assignment mechanism is ignorable - i.e. not    arrow from X to T - no confounding</li> </ol> <pre><code>graph LR\n  T ---&gt; Y\n  X ---&gt; Y</code></pre> <ol> <li>Causal structure of X confounding the effect of T on Y. The confounding is depicted    as the red dashed line.</li> </ol> <pre><code>graph LR\n  T --&gt; Y\n  X --&gt; T\n  X --&gt; Y</code></pre>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#positivity-aka-overlap","title":"Positivity (a.k.a Overlap)","text":"<p>Two ways to look at positivity a.k.a overlap:</p> <ol> <li>For all values of covariates \\(x\\) present in the population of subjects, \\(0 &lt; P(T=1|X=x) &lt; 1\\). That is the probability of treatment assignment for all values of covariate \\(x\\) should be non-zero.</li> <li>As overlap between the conditional distributions \\(P(X|T=0)\\) and \\(P(X|T=1)\\) is present.</li> </ol> <p>An example is:</p> <ul> <li>Data on previous promos were only applied to Cx that are more than 2 years since activation.</li> <li>This means you can\u2019t estimate reliably the outcome under T = 1 for Cx with &lt; 2 cohort age.</li> </ul>"},{"location":"Technical/Experimentation/Basic%20Probability%20and%20Statistics/#the-positivity-unconfoundedness-tradeoff","title":"The Positivity - Unconfoundedness Tradeoff","text":"<p>Similar to curse of dimensionality, as you increase the number of covariates you condition on the degree of overlap decreases.</p> <p>Therefore even if you can guarantee ignorability by controling for many confounders, you may still have a problem with overlap or positivity.</p>"},{"location":"Technical/Experimentation/Outline/","title":"Outline","text":"<p>Causal Inference</p> <ul> <li>Bayesian vs. Frequentist</li> </ul> <p>Basic Probability and Statistics</p> <ul> <li>Probability Theory</li> <li>Potential Outcomes Framework</li> <li>Graphical Models</li> <li>False Positives and False Negatives</li> <li>P-Values</li> <li>Power</li> <li>Confidence Interval</li> <li>CTR Variance</li> </ul> <p>Designing Experiments</p> <ul> <li>Why experiment?</li> <li>Landscape</li> <li>Product Development Cycle</li> <li>Measuring Impact</li> <li>What does the data look like</li> <li>How to randomize</li> <li>What could go wrong</li> <li>What to measure</li> <li>How to measure</li> <li>Compare</li> <li>Design and Monitor</li> <li>Interpret and Recommend Action</li> <li>A/A Test</li> </ul> <p>Overall Evaluation Criteria (OEC)</p> <p>Multiple Testing</p> <ul> <li>False Positives and Multiple Testing</li> <li>Omnibus test</li> </ul> <p>Tiered Metrics</p> <p>Central Limit Theorem and Handling Violated Assumptions</p> <ul> <li>When not to A/B Test</li> <li>What to do when you cannot A/B test</li> <li>How to check assumptions</li> <li>Bootstrap and Delta Method</li> <li>One-sided and Two Sided tests</li> <li>High Skew Remedies</li> <li>Small Samples</li> <li>Data Quality Checks</li> </ul> <p>Sequential Tests &amp; Variance Reduction</p> <ul> <li>Peeking and Sequential Testing</li> <li>Getting Results Faster</li> <li>Variance Reduction</li> <li>CUPED (vs Normal AB) and Crossover</li> <li>Fast Surrogates</li> <li>Pre-experiment Imbalance</li> </ul> <p>Multi-armed Bandits</p> <ul> <li>vs. AB</li> <li>vs. Contextual Bandits</li> </ul> <p>Marketplace and Network Effects</p>"},{"location":"Technical/Math/Linear%20Algebra/Numpy%20and%20PyTorch%20Tensors%20Guide/","title":"Numpy and PyTorch Tensors Guide","text":"<p>Two things we need to be able to do with data:</p> <ol> <li>acquire</li> <li>process</li> </ol> <p>Acquiring data also requires us to store it, and the most convenient tool we have at our disposal are <code>tensors</code> or <code>n-dimensional arrays</code>.</p>"},{"location":"Technical/Math/Linear%20Algebra/Numpy%20and%20PyTorch%20Tensors%20Guide/#initializing","title":"Initializing","text":"<pre><code>import numpy as np\nimport torch\n\n# Tensor: multi-dimensional array of numerical values\n# k = 1 axes is a vector\nnp_vector = np.random.rand(12)\ntorch_vector = torch.rand(12, dtype=torch.float32)\nprint(np_vector.shape)\nprint(torch_vector.shape)\n# k = 2 axes is a matrix\nnp_matrix = np.random.rand(12,2)\ntorch_matrix = torch.rand((12,2), dtype=torch.float32)\nprint(np_matrix.shape)\nprint(torch_matrix.shape)\n# k &gt; 2 axes is a kth order tensor\nnp_tensor = np.random.rand(12,2,1)\ntorch_tensor = torch.rand((12,2,1), dtype=torch.float32)\nprint(np_tensor.shape)\nprint(torch_tensor.shape)\n</code></pre> <p>Other ways to initialize:</p> <pre><code>torch.ones((2,3,4))\ntorch.zeros((2,3,4))\ntorch.randn((2,3,4)) # sample from normal distribution vs. uniform in rand\n</code></pre>"},{"location":"Technical/Math/Linear%20Algebra/Numpy%20and%20PyTorch%20Tensors%20Guide/#reshaping","title":"Reshaping","text":"<p>Change the shape of a tensor by either not changing:</p> <ol> <li>the number of elements</li> <li>the values of elements</li> </ol> <pre><code>np_tensor = np_tensor.reshape(6,4)\ntorch_tensor = torch_tensor.reshape(6,4)\n</code></pre> <p>Defining all dimensions is uneccessary - we only need to define n - 1 dims, the remaining is inferred.</p> <pre><code>np_tensor = np_tensor.reshape(6,-1)\ntorch_tensor = torch_tensor.reshape(6,-1)\n</code></pre>"},{"location":"Technical/Math/Linear%20Algebra/Numpy%20and%20PyTorch%20Tensors%20Guide/#operations","title":"Operations","text":""},{"location":"Technical/Math/Linear%20Algebra/Numpy%20and%20PyTorch%20Tensors%20Guide/#elementwise-operations","title":"Elementwise operations","text":"<p>Apply a standard scalar operation to each element of on array, or for two tensor inputs apply elementwise operations on each pair of elements.</p> <p>Thse include standard arithmetic operations (+, -, *, / and **).</p> <pre><code>x = torch.tensor([1.0, 2, 4, 8])\ny = torch.tensor([2, 2, 2, 2])\nx + y, x - y, x * y, x / y, x ** y\n</code></pre>"},{"location":"Technical/Math/Linear%20Algebra/Numpy%20and%20PyTorch%20Tensors%20Guide/#hadamard-product-elementwise-multiplication-of-two-matrices","title":"Hadamard product (Elementwise multiplication of two matrices)","text":"<p>Specifically, elementwise multiplication of two matrices is called their Hadamard product (math notation \\(\\odot\\)). Consider matrix \\(\\mathbf{B} \\in \\mathbb{R}^{m \\times n}\\) whose element of row $i` and column \\(j\\) is \\(b_{ij}\\). The Hadamard product of matrices \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\)</p> \\[    \\mathbf{A} \\odot \\mathbf{B} =    \\begin{bmatrix}        a_{11}  b_{11} &amp; a_{12}  b_{12} &amp; \\dots  &amp; a_{1n}  b_{1n} \\\\        a_{21}  b_{21} &amp; a_{22}  b_{22} &amp; \\dots  &amp; a_{2n}  b_{2n} \\\\        \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\        a_{m1}  b_{m1} &amp; a_{m2}  b_{m2} &amp; \\dots  &amp; a_{mn}  b_{mn}    \\end{bmatrix}. \\]"},{"location":"Technical/Math/Linear%20Algebra/Numpy%20and%20PyTorch%20Tensors%20Guide/#linear-algebra-operations","title":"Linear Algebra Operations","text":""},{"location":"Technical/Math/Linear%20Algebra/Numpy%20and%20PyTorch%20Tensors%20Guide/#transpose","title":"Transpose","text":"<pre><code>A = np.arange(20).reshape(5, 4)\nA\nA.T\n</code></pre> <p>As a special type of the square matrix, a symmetric matrix \\(\\mathbf{A}\\) is equal to its transpose: \\(\\mathbf{A} = \\mathbf{A}^\\top\\). Here we define a symmetric matrix <code>B</code>.</p> <pre><code>B = np.array([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\nB\nB == B.T\n</code></pre>"},{"location":"Technical/Math/Linear%20Algebra/Numpy%20and%20PyTorch%20Tensors%20Guide/#vector-dot-products","title":"Vector Dot Products","text":"<p>Given two vectors \\(\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^d\\), their dot product \\(\\mathbf{x}^\\top \\mathbf{y}\\) (or \\(\\langle \\mathbf{x}, \\mathbf{y} \\rangle\\)) is a sum over the products of the elements at the same position: \\(\\mathbf{x}^\\top \\mathbf{y} = \\sum_{i=1}^{d} x_i y_i\\).</p> <pre><code>x = torch.arange(4, dtype=torch.float32)\ny = torch.ones(4, dtype = torch.float32)\nx, y, torch.dot(x, y)\n</code></pre> <p>Dot products are useful in a wide range of contexts. For example, given some set of values, denoted by a vector \\(\\mathbf{x} \\in \\mathbb{R}^d\\) and a set of weights denoted by \\(\\mathbf{w} \\in \\mathbb{R}^d\\), the weighted sum of the values in \\(\\mathbf{x}\\) according to the weights \\(\\mathbf{w}\\) could be expressed as the dot product \\(\\mathbf{x}^\\top \\mathbf{w}\\). When the weights are non-negative and sum to one (i.e., \\(\\left(\\sum_{i=1}^{d} {w_i} = 1\\right)\\)), the dot product expresses a weighted average. After normalizing two vectors to have the unit length, the dot products express the cosine of the angle between them. We will formally introduce this notion of length later in this section.</p>"},{"location":"Technical/Math/Linear%20Algebra/Numpy%20and%20PyTorch%20Tensors%20Guide/#matrix-multiplications","title":"Matrix Multiplications","text":""},{"location":"Technical/Math/Linear%20Algebra/Numpy%20and%20PyTorch%20Tensors%20Guide/#concatentation-and-stacking","title":"Concatentation and Stacking","text":"<p>Provide the list of tensors and axis to concatenate against.</p> <pre><code>X = torch.arange(12, dtype=torch.float32).reshape((3,4))\nY = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\ntorch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)\n</code></pre>"},{"location":"Technical/Math/Linear%20Algebra/Numpy%20and%20PyTorch%20Tensors%20Guide/#summation","title":"Summation","text":"<p>Summing all the elements in the tensor yields a tensor with only one element. You can also sum along just a given axis.</p> <pre><code>X = torch.sum(X, 1) # sum along dim 1\nX = torch.sum() # sum all elements\n</code></pre>"},{"location":"Technical/Math/Linear%20Algebra/Numpy%20and%20PyTorch%20Tensors%20Guide/#non-reduction-sum","title":"Non-Reduction Sum","text":"<p>However, sometimes it can be useful to keep the number of axes unchanged when invoking the function for calculating the sum or mean.</p> <pre><code>sum_A = A.sum(axis=1, keepdims=True)\nsum_A\nA / sum_A\n</code></pre>"},{"location":"Technical/Math/Linear%20Algebra/Numpy%20and%20PyTorch%20Tensors%20Guide/#cumulative-sum","title":"Cumulative Sum","text":"<p>If we want to calculate the cumulative sum of elements of A along some axis, say axis=0 (row by row), we can call the cumsum function. This function will not reduce the input tensor along any axis.</p> <pre><code>A.cumsum(axis=0)\n</code></pre>"},{"location":"Technical/Math/Linear%20Algebra/Numpy%20and%20PyTorch%20Tensors%20Guide/#logical-operations","title":"Logical Operations","text":"<p>Sometimes, we want to construct a binary tensor via logical statements. Take X == Y as an example. For each position, if X and Y are equal at that position, the corresponding entry in the new tensor takes a value of 1, meaning that the logical statement X == Y is true at that position; otherwise that position takes 0.</p> <pre><code>X == Y\n</code></pre>"},{"location":"Technical/Math/Linear%20Algebra/Numpy%20and%20PyTorch%20Tensors%20Guide/#broadcasting","title":"Broadcasting","text":"<p>Under certain conditions, even when shapes differ, we can still perform elementwise operations by invoking the broadcasting mechanism. This mechanism works in the following way: First, expand one or both arrays by copying elements appropriately so that after this transformation, the two tensors have the same shape. Second, carry out the elementwise operations on the resulting arrays.</p> <pre><code>a = torch.arange(3).reshape((3, 1))\nb = torch.arange(2).reshape((1, 2))\na, b\n</code></pre> <p>Since <code>a</code> and <code>b</code> are \\(3\\times1\\) and \\(1\\times2\\) matrices respectively, their shapes do not match up if we want to add them. We broadcast the entries of both matrices into a larger \\(3\\times2\\) matrix as follows: for matrix <code>a</code> it replicates the columns and for matrix <code>b</code> it replicates the rows before adding up both elementwise.</p> <pre><code>a + b\n</code></pre>"},{"location":"Technical/Math/Linear%20Algebra/Numpy%20and%20PyTorch%20Tensors%20Guide/#indexing-an-slicing","title":"Indexing an Slicing","text":"<p>Just as in any other Python array, elements in a tensor can be accessed by index. As in any Python array, the first element has index 0 and ranges are specified to include the first but before the last element. As in standard Python lists, we can access elements according to their relative position to the end of the list by using negative indices.</p> <p>Thus, [-1] selects the last element and [1:3] selects the second and the third elements as follows:</p> <pre><code>X[-1], X[1:3]\n</code></pre> <p>Beyond reading, we can also write elements of a matrix by specifying indices.</p> <pre><code>X[1, 2] = 9\nX\n\nX[0:2, :] = 12\nX\n</code></pre>"},{"location":"Technical/Math/Linear%20Algebra/Numpy%20and%20PyTorch%20Tensors%20Guide/#saving-memory","title":"Saving Memory","text":"<p>Running operations can cause new memory to be allocated to host results. For example, if we write Y = X + Y, we will dereference the tensor that Y used to point to and instead point Y at the newly allocated memory. In the following example, we demonstrate this with Python\u2019s id() function, which gives us the exact address of the referenced object in memory. After running Y = Y + X, we will find that id(Y) points to a different location. That is because Python first evaluates Y + X, allocating new memory for the result and then makes Y point to this new location in memory.</p> <pre><code>before = id(Y)\nY = Y + X\nid(Y) == before\n</code></pre> <p>This might be undesirable for two reasons. First, we do not want to run around allocating memory unnecessarily all the time. In machine learning, we might have hundreds of megabytes of parameters and update all of them multiple times per second. Typically, we will want to perform these updates in place. Second, we might point at the same parameters from multiple variables. If we do not update in place, other references will still point to the old memory location, making it possible for parts of our code to inadvertently reference stale parameters.</p> <p>Fortunately, performing in-place operations is easy. We can assign the result of an operation to a previously allocated array with slice notation, e.g., Y[:] = . To illustrate this concept, we first create a new matrix Z with the same shape as another Y, using zeros_like to allocate a block of 0 entries. <pre><code>Z = torch.zeros_like(Y)\nprint('id(Z):', id(Z))\nZ[:] = X + Y\nprint('id(Z):', id(Z))\n</code></pre>"},{"location":"Technical/Object%20Oriented%20Programming/adapter_pattern/","title":"Adapter pattern","text":"<pre><code>class Empty(Exception):\n    \"\"\"Error attempting to access an element from an empty container.\"\"\"\n    pass\n\nclass ArrayStack:\n    \"\"\"LIFO stack implementation using Python list as underlying storage\"\"\"\n\n    def __init__(self):\n        self._data = []\n\n    def __len__(self):\n        return len(self._data)\n\n    def is_empty(self):\n        return len(self._data) == 0\n\n    def push(self, e):\n        self._data.append(e)\n\n    def top(self):\n        if self.is_empty():\n            raise Empty('Stack is Empty')\n        return self._data[-1]\n\n    def pop(self):\n        if self.is_empty():\n            raise Empty('Stack is Empty')\n        return self._data.pop()\n</code></pre>"},{"location":"Technical/Object%20Oriented%20Programming/adapter_pattern/#adapter-pattern","title":"Adapter Pattern","text":"<p>The adapter design pattern applies to any context where we effectively want to modify an existing class so that its methods match those a related, but different, class or interface. </p> <p>One general way to apply the adapter pattern is to define a new class in such a way that it contains an instance of the existing class as a hidden field, and then to implement each method of the new class using methods of this hidden instance variable. </p> <p>By applying the adapter pattern in this way, we have created a new class that performs some of the same functions as an existing class, but repacked in a more convenient way. </p> <p>An example is to implement an Array based Stack using a Python <code>list</code> - with a simple example shown below.</p>"}]}